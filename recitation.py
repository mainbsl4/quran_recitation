# import whisper
# from fuzzywuzzy import fuzz
# from difflib import SequenceMatcher

# # Load Whisper model
# model = whisper.load_model("large")

# # Convert audio to text (Arabic)
# def audio_to_text(audio_file_path):
#     global model
#     result = model.transcribe(audio_file_path, language="ar")
#     return result["text"].strip()

# # Function to highlight character-level differences
# def highlight_differences(original, compared):
#     matcher = SequenceMatcher(None, original, compared)

#     output = []
#     for tag, i1, i2, j1, j2 in matcher.get_opcodes():
#         if tag == 'equal':
#             output.append(original[i1:i2])
#         elif tag == 'replace':
#             output.append(f"\nâŒ Pronunciation mismatch: '{original[i1:i2]}' â†’ '{compared[j1:j2]}'")
#         elif tag == 'delete':
#             output.append(f"\nâŒ Missing in input: '{original[i1:i2]}'")
#         elif tag == 'insert':
#             output.append(f"\nâŒ Extra in input: '{compared[j1:j2]}'")

#     return ''.join(output) if output else "âœ… Perfect pronunciation (with tashdid & harakat)"

# # Function to highlight word-level differences
# def word_level_diff(original, compared):
#     words1 = original.split()
#     words2 = compared.split()

#     d = SequenceMatcher(None, words1, words2)
#     differences = []
#     for tag, i1, i2, j1, j2 in d.get_opcodes():
#         if tag == 'replace':
#             differences.append(f"âŒ Word mismatch: '{' '.join(words1[i1:i2])}' â†’ '{' '.join(words2[j1:j2])}'")
#         elif tag == 'delete':
#             differences.append(f"âŒ Missing word: '{' '.join(words1[i1:i2])}'")
#         elif tag == 'insert':
#             differences.append(f"âŒ Extra word: '{' '.join(words2[j1:j2])}'")

#     return "\n".join(differences) if differences else "âœ… All words correct"

# # ---- MAIN EXECUTION ----

# # Step 1: Get transcription from audio
# input_sentence = audio_to_text("./1. Surah Al-Fatihah 1st verse.mp3")
# print("ðŸŽ¤ Transcribed Text from Audio:")
# print(input_sentence)

# # Step 2: Reference sentences (Quran Ayat list)
# sentence_list = [
#   "Ø¨Ø³Ù… Ø§Ù„Ù„Ù‡ Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø±Ø­ÙŠÙ…",
#   "Ø¨ÙØ³Ù’Ù…Ù Ø§Ù„Ù„Ù‘ÙŽÙ‡Ù Ø§Ù„Ø±Ù‘ÙŽØ­Ù’Ù…ÙŽÙ°Ù†Ù Ø§Ù„Ø±Ù‘ÙŽØ­ÙÙŠÙ…Ù",
#   "Ø§Ù„Ù’Ø­ÙŽÙ…Ù’Ø¯Ù Ù„ÙÙ„Ù‘ÙŽÙ‡Ù Ø±ÙŽØ¨Ù‘Ù Ø§Ù„Ù’Ø¹ÙŽØ§Ù„ÙŽÙ…ÙÙŠÙ†ÙŽ",
#   "Ø§Ù‡Ù’Ø¯ÙÙ†ÙŽØ§ Ø§Ù„ØµÙ‘ÙØ±ÙŽØ§Ø·ÙŽ Ø§Ù„Ù’Ù…ÙØ³Ù’ØªÙŽÙ‚ÙÙŠÙ…ÙŽ",
#   "Ù‚ÙÙ„Ù’ Ù‡ÙÙˆÙŽ Ø§Ù„Ù„Ù‘ÙŽÙ‡Ù Ø£ÙŽØ­ÙŽØ¯ÙŒ",
#   "Ø§Ù„Ù„Ù‘ÙŽÙ‡Ù Ø§Ù„ØµÙ‘ÙŽÙ…ÙŽØ¯Ù",
#   "Ù„ÙŽÙ…Ù’ ÙŠÙŽÙ„ÙØ¯Ù’ ÙˆÙŽÙ„ÙŽÙ…Ù’ ÙŠÙÙˆÙ„ÙŽØ¯Ù’",
#   "ÙˆÙŽÙ„ÙŽÙ…Ù’ ÙŠÙŽÙƒÙÙ† Ù„Ù‘ÙŽÙ‡Ù ÙƒÙÙÙÙˆÙ‹Ø§ Ø£ÙŽØ­ÙŽØ¯ÙŒ",
#   "Ø¥ÙÙ†Ù‘ÙŽ Ø§Ù„Ù„Ù‘ÙŽÙ‡ÙŽ Ù…ÙŽØ¹ÙŽ Ø§Ù„Ù‘ÙŽØ°ÙÙŠÙ†ÙŽ Ø§ØªÙ‘ÙŽÙ‚ÙŽÙˆÙ’Ø§ ÙˆÙŽØ§Ù„Ù‘ÙŽØ°ÙÙŠÙ†ÙŽ Ù‡ÙÙ… Ù…Ù‘ÙØ­Ù’Ø³ÙÙ†ÙÙˆÙ†ÙŽ",
#   "ÙˆÙŽØ¹ÙØ¨ÙŽØ§Ø¯Ù Ø§Ù„Ø±Ù‘ÙŽØ­Ù’Ù…ÙŽÙ°Ù†Ù Ø§Ù„Ù‘ÙŽØ°ÙÙŠÙ†ÙŽ ÙŠÙŽÙ…Ù’Ø´ÙÙˆÙ†ÙŽ Ø¹ÙŽÙ„ÙŽÙ‰ Ø§Ù„Ù’Ø£ÙŽØ±Ù’Ø¶Ù Ù‡ÙŽÙˆÙ’Ù†Ù‹Ø§",
#   "ÙˆÙŽÙ„ÙŽÙ‚ÙŽØ¯Ù’ ÙŠÙŽØ³Ù‘ÙŽØ±Ù’Ù†ÙŽØ§ Ø§Ù„Ù’Ù‚ÙØ±Ù’Ø¢Ù†ÙŽ Ù„ÙÙ„Ø°Ù‘ÙÙƒÙ’Ø±Ù ÙÙŽÙ‡ÙŽÙ„Ù’ Ù…ÙÙ† Ù…Ù‘ÙØ¯Ù‘ÙŽÙƒÙØ±Ù"
# ]

# # Step 3: Find the best match
# matches = [(sentence, fuzz.ratio(input_sentence, sentence)) for sentence in sentence_list]
# matches.sort(key=lambda x: x[1], reverse=True)
# best_match_sentence, score = matches[0]

# print("\nâœ… Top match found:")
# print(f"Reference Sentence: {best_match_sentence}")
# print(f"Similarity Score: {score}%")

# # Step 4: Show differences
# print("\nðŸ”Ž Character-level check:")
# print(highlight_differences(input_sentence, best_match_sentence))

# print("\nðŸ”Ž Word-level check:")
# print(word_level_diff(input_sentence, best_match_sentence))
# #
















# import whisper
# from fuzzywuzzy import fuzz
# from difflib import SequenceMatcher
# import re

# # Load Whisper model
# model = whisper.load_model("large")

# # Convert audio to text (Arabic)
# def audio_to_text(audio_file_path):
#     global model
#     result = model.transcribe(audio_file_path, language="ar")
#     return result["text"].strip()

# # Character-level differences
# def highlight_differences(original, compared):
#     matcher = SequenceMatcher(None, original, compared)
#     output = []
#     for tag, i1, i2, j1, j2 in matcher.get_opcodes():
#         if tag == 'equal':
#             output.append(original[i1:i2])
#         elif tag == 'replace':
#             output.append(f"\nâŒ Pronunciation mismatch: '{original[i1:i2]}' â†’ '{compared[j1:j2]}'")
#         elif tag == 'delete':
#             output.append(f"\nâŒ Missing in input: '{original[i1:i2]}'")
#         elif tag == 'insert':
#             output.append(f"\nâŒ Extra in input: '{compared[j1:j2]}'")
#     return ''.join(output) if output else "âœ… Perfect pronunciation (with tashdid & harakat)"

# # Word-level differences
# def word_level_diff(original, compared):
#     words1 = original.split()
#     words2 = compared.split()
#     d = SequenceMatcher(None, words1, words2)
#     differences = []
#     for tag, i1, i2, j1, j2 in d.get_opcodes():
#         if tag == 'replace':
#             differences.append(f"âŒ Word mismatch: '{' '.join(words1[i1:i2])}' â†’ '{' '.join(words2[j1:j2])}'")
#         elif tag == 'delete':
#             differences.append(f"âŒ Missing word: '{' '.join(words1[i1:i2])}'")
#         elif tag == 'insert':
#             differences.append(f"âŒ Extra word: '{' '.join(words2[j1:j2])}'")
#     return "\n".join(differences) if differences else "âœ… All words correct"

# # Harakat / Tashdid checker
# def check_harakat(original, compared):
#     # Arabic diacritics set
#     diacritics = {
#         "ÙŽ": "Fatha",
#         "Ù‹": "Tanwin Fath",
#         "Ù": "Kasra",
#         "Ù": "Tanwin Kasr",
#         "Ù": "Damma",
#         "ÙŒ": "Tanwin Damm",
#         "Ù’": "Sukun",
#         "Ù‘": "Shadda"
#     }

#     issues = []
#     for i, (o_char, c_char) in enumerate(zip(original, compared)):
#         if o_char != c_char:
#             if o_char in diacritics or c_char in diacritics:
#                 issues.append(f"âŒ Harakat mismatch at pos {i}: '{o_char}' â†’ '{c_char}'")

#     if not issues:
#         return "âœ… All Harakat & Tashdid correct"
#     return "\n".join(issues)

# # ---- MAIN EXECUTION ----

# # Step 1: Get transcription from audio
# input_sentence = audio_to_text("./1. Surah Al-Fatihah 1st verse.mp3")
# print("ðŸŽ¤ Transcribed Text from Audio:")
# print(input_sentence)

# # Step 2: Reference sentences (Quran Ayat list)
# sentence_list = [
#   "Ø¨Ø³Ù… Ø§Ù„Ù„Ù‡ Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø±Ø­ÙŠÙ…",
#   "Ø¨ÙØ³Ù’Ù…Ù Ø§Ù„Ù„Ù‘ÙŽÙ‡Ù Ø§Ù„Ø±Ù‘ÙŽØ­Ù’Ù…ÙŽÙ°Ù†Ù Ø§Ù„Ø±Ù‘ÙŽØ­ÙÙŠÙ…Ù",
#   "Ø§Ù„Ù’Ø­ÙŽÙ…Ù’Ø¯Ù Ù„ÙÙ„Ù‘ÙŽÙ‡Ù Ø±ÙŽØ¨Ù‘Ù Ø§Ù„Ù’Ø¹ÙŽØ§Ù„ÙŽÙ…ÙÙŠÙ†ÙŽ",
#   "Ø§Ù‡Ù’Ø¯ÙÙ†ÙŽØ§ Ø§Ù„ØµÙ‘ÙØ±ÙŽØ§Ø·ÙŽ Ø§Ù„Ù’Ù…ÙØ³Ù’ØªÙŽÙ‚ÙÙŠÙ…ÙŽ",
#   "Ù‚ÙÙ„Ù’ Ù‡ÙÙˆÙŽ Ø§Ù„Ù„Ù‘ÙŽÙ‡Ù Ø£ÙŽØ­ÙŽØ¯ÙŒ",
#   "Ø§Ù„Ù„Ù‘ÙŽÙ‡Ù Ø§Ù„ØµÙ‘ÙŽÙ…ÙŽØ¯Ù",
#   "Ù„ÙŽÙ…Ù’ ÙŠÙŽÙ„ÙØ¯Ù’ ÙˆÙŽÙ„ÙŽÙ…Ù’ ÙŠÙÙˆÙ„ÙŽØ¯Ù’",
#   "ÙˆÙŽÙ„ÙŽÙ…Ù’ ÙŠÙŽÙƒÙÙ† Ù„Ù‘ÙŽÙ‡Ù ÙƒÙÙÙÙˆÙ‹Ø§ Ø£ÙŽØ­ÙŽØ¯ÙŒ",
#   "Ø¥ÙÙ†Ù‘ÙŽ Ø§Ù„Ù„Ù‘ÙŽÙ‡ÙŽ Ù…ÙŽØ¹ÙŽ Ø§Ù„Ù‘ÙŽØ°ÙÙŠÙ†ÙŽ Ø§ØªÙ‘ÙŽÙ‚ÙŽÙˆÙ’Ø§ ÙˆÙŽØ§Ù„Ù‘ÙŽØ°ÙÙŠÙ†ÙŽ Ù‡ÙÙ… Ù…Ù‘ÙØ­Ù’Ø³ÙÙ†ÙÙˆÙ†ÙŽ",
#   "ÙˆÙŽØ¹ÙØ¨ÙŽØ§Ø¯Ù Ø§Ù„Ø±Ù‘ÙŽØ­Ù’Ù…ÙŽÙ°Ù†Ù Ø§Ù„Ù‘ÙŽØ°ÙÙŠÙ†ÙŽ ÙŠÙŽÙ…Ù’Ø´ÙÙˆÙ†ÙŽ Ø¹ÙŽÙ„ÙŽÙ‰ Ø§Ù„Ù’Ø£ÙŽØ±Ù’Ø¶Ù Ù‡ÙŽÙˆÙ’Ù†Ù‹Ø§",
#   "ÙˆÙŽÙ„ÙŽÙ‚ÙŽØ¯Ù’ ÙŠÙŽØ³Ù‘ÙŽØ±Ù’Ù†ÙŽØ§ Ø§Ù„Ù’Ù‚ÙØ±Ù’Ø¢Ù†ÙŽ Ù„ÙÙ„Ø°Ù‘ÙÙƒÙ’Ø±Ù ÙÙŽÙ‡ÙŽÙ„Ù’ Ù…ÙÙ† Ù…Ù‘ÙØ¯Ù‘ÙŽÙƒÙØ±Ù"
# ]

# # Step 3: Find the best match
# matches = [(sentence, fuzz.ratio(input_sentence, sentence)) for sentence in sentence_list]
# matches.sort(key=lambda x: x[1], reverse=True)
# best_match_sentence, score = matches[0]

# print("\nâœ… Top match found:")
# print(f"Reference Sentence: {best_match_sentence}")
# print(f"Similarity Score: {score}%")

# # Step 4: Show differences
# print("\nðŸ”Ž Character-level check:")
# print(highlight_differences(input_sentence, best_match_sentence))

# print("\nðŸ”Ž Word-level check:")
# print(word_level_diff(input_sentence, best_match_sentence))

# print("\nðŸ”Ž Harakat & Tashdid check:")
# print(check_harakat(input_sentence, best_match_sentence))




































# import whisper
# from fuzzywuzzy import fuzz
# from difflib import SequenceMatcher
# import re

# # --- Load Whisper model ---
# model = whisper.load_model("large")

# # --- Arabic diacritics / tashkeel set ---
# ARABIC_DIACRITICS = set([
#     '\u0610','\u0611','\u0612','\u0613','\u0614','\u0615','\u0616','\u0617','\u0618','\u0619','\u061A',
#     '\u064B','\u064C','\u064D','\u064E','\u064F','\u0650','\u0651','\u0652','\u0653','\u0654','\u0655'
# ])
# # make a small friendly map name (optional)
# DIACRITIC_NAMES = {
#     "ÙŽ": "Fatha", "Ù‹": "Tanwin-Fath", "Ù": "Kasra", "Ù": "Tanwin-Kasr",
#     "Ù": "Damma", "ÙŒ": "Tanwin-Damm", "Ù’": "Sukun", "Ù‘": "Shadda"
# }

# # --- Utility: transcribe audio to text (Arabic) ---
# def audio_to_text(audio_file_path):
#     global model
#     result = model.transcribe(audio_file_path, language="ar")
#     return result["text"].strip()

# # --- Utility: split text into base characters with attached diacritics ---
# def split_bases_and_diacritics(text):
#     """
#     Return list of tuples: [(base_char, diacritics_str), ...]
#     Spaces and punctuation are returned as base chars with empty diacritics.
#     """
#     parts = []
#     for ch in text:
#         if not parts:
#             parts.append([ch, ""])
#             continue
#         if ch in ARABIC_DIACRITICS:
#             # append diacritic to last base (if any)
#             parts[-1][1] += ch
#         else:
#             # new base character
#             parts.append([ch, ""])
#     # convert to tuples
#     return [(b, d) for b, d in parts]

# # --- Character-level diff with clear messages ---
# def highlight_differences(original, compared):
#     matcher = SequenceMatcher(None, original, compared)
#     output = []
#     for tag, i1, i2, j1, j2 in matcher.get_opcodes():
#         if tag == 'equal':
#             output.append(original[i1:i2])
#         elif tag == 'replace':
#             output.append(f"\nâŒ Replace: '{original[i1:i2]}'  â†’  '{compared[j1:j2]}'")
#         elif tag == 'delete':
#             output.append(f"\nâŒ Missing in input: '{original[i1:i2]}'")
#         elif tag == 'insert':
#             output.append(f"\nâŒ Extra in input: '{compared[j1:j2]}'")
#     return ''.join(output) if output else "âœ… No character-level differences."

# # --- Word-level diff (word alignment) ---
# def word_level_diff(original, compared):
#     words1 = original.split()
#     words2 = compared.split()
#     d = SequenceMatcher(None, words1, words2)
#     differences = []
#     for tag, i1, i2, j1, j2 in d.get_opcodes():
#         if tag == 'replace':
#             differences.append(f"âŒ Word mismatch: '{' '.join(words1[i1:i2])}' â†’ '{' '.join(words2[j1:j2])}'")
#         elif tag == 'delete':
#             differences.append(f"âŒ Missing word: '{' '.join(words1[i1:i2])}'")
#         elif tag == 'insert':
#             differences.append(f"âŒ Extra word: '{' '.join(words2[j1:j2])}'")
#     return "\n".join(differences) if differences else "âœ… All words correct."

# # --- Harakat & Tashdid (Shadda) checker ---
# def check_harakat_and_tashdid(original, compared):
#     """
#     Compares diacritics and specifically checks presence/absence of Shadda (Ù‘).
#     Returns a dict with lists of issues and a brief summary.
#     """
#     o_list = split_bases_and_diacritics(original)
#     c_list = split_bases_and_diacritics(compared)

#     # Build sequences of base chars only for alignment
#     o_bases = [b for b, d in o_list]
#     c_bases = [b for b, d in c_list]

#     sm = SequenceMatcher(None, o_bases, c_bases)
#     issues = []
#     pos_index = 0  # base-character index approximate (counts matched bases)
#     for tag, i1, i2, j1, j2 in sm.get_opcodes():
#         if tag == 'equal':
#             # iterate through matched ranges and compare diacritics
#             for oi, ci in zip(range(i1, i2), range(j1, j2)):
#                 o_base, o_diac = o_list[oi]
#                 c_base, c_diac = c_list[ci]
#                 # Check shadda specifically
#                 o_has_shadda = 'Ù‘' in o_diac
#                 c_has_shadda = 'Ù‘' in c_diac
#                 if o_has_shadda and not c_has_shadda:
#                     issues.append(f"âŒ Missing Shadda (Ù‘) on '{o_base}' at base-pos {oi} (expected shadda).")
#                 elif (not o_has_shadda) and c_has_shadda:
#                     issues.append(f"âŒ Extra Shadda (Ù‘) on '{c_base}' at base-pos {ci} (input has shadda but reference doesn't).")
#                 # Check other diacritics differences (presence/absence)
#                 # list diacritics except shadda
#                 o_other = ''.join([ch for ch in o_diac if ch != 'Ù‘'])
#                 c_other = ''.join([ch for ch in c_diac if ch != 'Ù‘'])
#                 if o_other != c_other:
#                     issues.append(f"âŒ Diacritics differ on '{o_base}' at base-pos {oi}: expected '{o_other or 'â€”'}' vs input '{c_other or 'â€”'}'.")
#                 pos_index += 1
#         elif tag == 'replace':
#             # Bases differ -> but still check if diacritics include shadda and warn
#             # For each pair in ranges, report base mismatch and diacritic differences if any
#             length = max(i2 - i1, j2 - j1)
#             for k in range(length):
#                 oi = i1 + k
#                 ci = j1 + k
#                 o_text = o_list[oi] if oi < len(o_list) else ("â€”", "")
#                 c_text = c_list[ci] if ci < len(c_list) else ("â€”", "")
#                 issues.append(f"âŒ Base mismatch at base-pos approx {oi}: expected '{o_text[0]}' (diacritics '{o_text[1] or 'â€”'}') â†’ input '{c_text[0]}' (diacritics '{c_text[1] or 'â€”'}').")
#         elif tag == 'delete':
#             for oi in range(i1, i2):
#                 o_base, o_diac = o_list[oi]
#                 if 'Ù‘' in o_diac:
#                     issues.append(f"âŒ Missing base (and its Shadda) in input at base-pos {oi}: '{o_base}' with diacritics '{o_diac}'")
#                 else:
#                     issues.append(f"âŒ Missing base in input at base-pos {oi}: '{o_base}'")
#         elif tag == 'insert':
#             for ci in range(j1, j2):
#                 c_base, c_diac = c_list[ci]
#                 if 'Ù‘' in c_diac:
#                     issues.append(f"âŒ Extra base in input with Shadda at base-pos {ci}: '{c_base}' (diacritics '{c_diac}')")
#                 else:
#                     issues.append(f"âŒ Extra base in input at base-pos {ci}: '{c_base}' (diacritics '{c_diac or 'â€”'}')")

#     summary = "âœ… No harakat/tashdid issues." if not issues else f"âŒ Found {len(issues)} harakat/tashdid issues."
#     return {"summary": summary, "issues": issues}

# # --- MAIN EXECUTION ---
# if __name__ == "__main__":
#     # 1) Transcribe audio
#     audio_path = "./1. Surah Al-Fatihah 1st verse.mp3"
#     input_sentence = audio_to_text(audio_path)
#     print("ðŸŽ¤ Transcribed Text:")
#     print(input_sentence)
#     print("-" * 60)

#     # 2) Reference sentences list (you can extend)
#     sentence_list = [
#       "Ø¨Ø³Ù… Ø§Ù„Ù„Ù‡ Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø±Ø­ÙŠÙ…",
#       "Ø¨ÙØ³Ù’Ù…Ù Ø§Ù„Ù„Ù‘ÙŽÙ‡Ù Ø§Ù„Ø±Ù‘ÙŽØ­Ù’Ù…ÙŽÙ°Ù†Ù Ø§Ù„Ø±Ù‘ÙŽØ­ÙÙŠÙ…Ù",
#       "Ø§Ù„Ù’Ø­ÙŽÙ…Ù’Ø¯Ù Ù„ÙÙ„Ù‘ÙŽÙ‡Ù Ø±ÙŽØ¨Ù‘Ù Ø§Ù„Ù’Ø¹ÙŽØ§Ù„ÙŽÙ…ÙÙŠÙ†ÙŽ",
#       "Ø§Ù‡Ù’Ø¯ÙÙ†ÙŽØ§ Ø§Ù„ØµÙ‘ÙØ±ÙŽØ§Ø·ÙŽ Ø§Ù„Ù’Ù…ÙØ³Ù’ØªÙŽÙ‚ÙÙŠÙ…ÙŽ",
#       "Ù‚ÙÙ„Ù’ Ù‡ÙÙˆÙŽ Ø§Ù„Ù„Ù‘ÙŽÙ‡Ù Ø£ÙŽØ­ÙŽØ¯ÙŒ",
#       "Ø§Ù„Ù„Ù‘ÙŽÙ‡Ù Ø§Ù„ØµÙ‘ÙŽÙ…ÙŽØ¯Ù",
#       "Ù„ÙŽÙ…Ù’ ÙŠÙŽÙ„ÙØ¯Ù’ ÙˆÙŽÙ„ÙŽÙ…Ù’ ÙŠÙÙˆÙ„ÙŽØ¯Ù’",
#       "ÙˆÙŽÙ„ÙŽÙ…Ù’ ÙŠÙŽÙƒÙÙ† Ù„Ù‘ÙŽÙ‡Ù ÙƒÙÙÙÙˆÙ‹Ø§ Ø£ÙŽØ­ÙŽØ¯ÙŒ",
#       "Ø¥ÙÙ†Ù‘ÙŽ Ø§Ù„Ù„Ù‘ÙŽÙ‡ÙŽ Ù…ÙŽØ¹ÙŽ Ø§Ù„Ù‘ÙŽØ°ÙÙŠÙ†ÙŽ Ø§ØªÙ‘ÙŽÙ‚ÙŽÙˆÙ’Ø§ ÙˆÙŽØ§Ù„Ù‘ÙŽØ°ÙÙŠÙ†ÙŽ Ù‡ÙÙ… Ù…Ù‘ÙØ­Ù’Ø³ÙÙ†ÙÙˆÙ†ÙŽ",
#       "ÙˆÙŽØ¹ÙØ¨ÙŽØ§Ø¯Ù Ø§Ù„Ø±Ù‘ÙŽØ­Ù’Ù…ÙŽÙ°Ù†Ù Ø§Ù„Ù‘ÙŽØ°ÙÙŠÙ†ÙŽ ÙŠÙŽÙ…Ù’Ø´ÙÙˆÙ†ÙŽ Ø¹ÙŽÙ„ÙŽÙ‰ Ø§Ù„Ù’Ø£ÙŽØ±Ù’Ø¶Ù Ù‡ÙŽÙˆÙ’Ù†Ù‹Ø§",
#       "ÙˆÙŽÙ„ÙŽÙ‚ÙŽØ¯Ù’ ÙŠÙŽØ³Ù‘ÙŽØ±Ù’Ù†ÙŽØ§ Ø§Ù„Ù’Ù‚ÙØ±Ù’Ø¢Ù†ÙŽ Ù„ÙÙ„Ø°Ù‘ÙÙƒÙ’Ø±Ù ÙÙŽÙ‡ÙŽÙ„Ù’ Ù…ÙÙ† Ù…Ù‘ÙØ¯Ù‘ÙŽÙƒÙØ±Ù"
#     ]

#     # 3) Find best match using fuzzy ratio (keeps original diacritics; no normalization)
#     matches = [(sentence, fuzz.ratio(input_sentence, sentence)) for sentence in sentence_list]
#     matches.sort(key=lambda x: x[1], reverse=True)
#     best_match_sentence, score = matches[0]

#     print("âœ… Top match (reference):")
#     print(best_match_sentence)
#     print(f"Similarity score: {score}%")
#     print("-" * 60)

#     # 4) Character-level & word-level diffs
#     print("ðŸ”Ž Character-level differences:")
#     print(highlight_differences(input_sentence, best_match_sentence))
#     print("-" * 40)
#     print("ðŸ”Ž Word-level differences:")
#     print(word_level_diff(input_sentence, best_match_sentence))
#     print("-" * 40)

#     # 5) Harakat & Tashdid check (detailed)
#     harakat_report = check_harakat_and_tashdid(best_match_sentence, input_sentence)
#     print("ðŸ”Ž Harakat & Tashdid check summary:")
#     print(harakat_report["summary"])
#     if harakat_report["issues"]:
#         print("\nDetailed issues:")
#         for issue in harakat_report["issues"]:
#             print(issue)
#     else:
#         print("No issues found.")






























# # -*- coding: utf-8 -*-
# """
# à¦•à§à¦°à¦†à¦¨ à¦‰à¦šà§à¦šà¦¾à¦°à¦£ à¦“ à¦¤à¦¾à¦¸à¦¦à§€à¦¦ (à¦¶à¦¾à¦¦à§à¦¦à¦¾) à¦šà§‡à¦•à¦¾à¦°
# ------------------------------------------
# à¦à¦‡ à¦•à§‹à¦¡:
# - à¦…à¦¡à¦¿à¦“ à¦¥à§‡à¦•à§‡ à¦†à¦°à¦¬à¦¿ à¦Ÿà§‡à¦•à§à¦¸à¦Ÿ à¦¤à§ˆà¦°à¦¿ à¦•à¦°à¦¬à§‡
# - à¦¶à¦¾à¦¦à§à¦¦à¦¾ (Ù€Ù‘) à¦šà§‡à¦• à¦•à¦°à¦¬à§‡
# - à¦‰à¦šà§à¦šà¦¾à¦°à¦£à§‡à¦° à¦®à¦¾à¦¨ à¦®à§‚à¦²à§à¦¯à¦¾à¦¯à¦¼à¦¨ à¦•à¦°à¦¬à§‡
# - à¦¤à§à¦°à§à¦Ÿà¦¿ à¦›à¦¾à¦¡à¦¼à¦¾à¦‡ à¦•à¦¾à¦œ à¦•à¦°à¦¬à§‡
# """

# import torch
# import torchaudio
# from transformers import AutoProcessor, Wav2Vec2ForCTC
# from fuzzywuzzy import fuzz
# from difflib import SequenceMatcher
# import warnings

# # à¦“à¦¯à¦¼à¦¾à¦°à§à¦¨à¦¿à¦‚ à¦‰à¦ªà§‡à¦•à§à¦·à¦¾ à¦•à¦°à§à¦¨ (torchaudio à¦­à¦¬à¦¿à¦·à§à¦¯à¦¤à§‡à¦° à¦œà¦¨à§à¦¯ à¦¸à¦¤à¦°à§à¦• à¦•à¦°à¦›à§‡)
# warnings.filterwarnings("ignore", category=UserWarning, module="torchaudio")

# # ========================================
# # 1. à¦®à¦¡à§‡à¦² à¦²à§‹à¦¡ (à¦†à¦°à¦¬à¦¿ à¦¸à¦®à¦°à§à¦¥à¦¨à¦•à¦¾à¦°à§€)
# # ========================================
# print("ðŸ”„ à¦®à¦¡à§‡à¦² à¦²à§‹à¦¡ à¦¹à¦šà§à¦›à§‡...")

# try:
#     # processor = AutoProcessor.from_pretrained("facebook/wav2vec2-large-xlsr-53")
#     # model = Wav2Vec2ForCTC.from_pretrained("facebook/wav2vec2-large-xlsr-53")
#     processor = AutoProcessor.from_pretrained("jonatasgrosman/wav2vec2-large-xlsr-53-arabic")
#     model = Wav2Vec2ForCTC.from_pretrained("jonatasgrosman/wav2vec2-large-xlsr-53-arabic")
#     print("âœ… à¦®à¦¡à§‡à¦² à¦¸à¦«à¦²à¦­à¦¾à¦¬à§‡ à¦²à§‹à¦¡ à¦¹à¦¯à¦¼à§‡à¦›à§‡!")
# except Exception as e:
#     print("âŒ à¦®à¦¡à§‡à¦² à¦²à§‹à¦¡ à¦•à¦°à¦¤à§‡ à¦¬à§à¦¯à¦°à§à¦¥ à¦¹à¦¯à¦¼à§‡à¦›à§‡:", str(e))
#     print("ðŸ’¡ à¦‡à¦¨à§à¦Ÿà¦¾à¦°à¦¨à§‡à¦Ÿ à¦šà¦¾à¦²à§ à¦•à¦°à§à¦¨ à¦¬à¦¾ à¦­à¦¿à¦ªà¦¿à¦à¦¨ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§à¦¨à¥¤")
#     print("ðŸ’¡ à¦…à¦¥à¦¬à¦¾ à¦®à§à¦¯à¦¾à¦¨à§à¦¯à¦¼à¦¾à¦²à¦¿ à¦®à¦¡à§‡à¦² à¦¡à¦¾à¦‰à¦¨à¦²à§‹à¦¡ à¦•à¦°à§à¦¨à¥¤")
#     exit(1)  # à¦®à¦¡à§‡à¦² à¦¨à¦¾ à¦¥à¦¾à¦•à¦²à§‡ à¦ªà§à¦°à§‹à¦—à§à¦°à¦¾à¦® à¦¬à¦¨à§à¦§ à¦•à¦°à§à¦¨

# # ========================================
# # 2. à¦¶à¦¾à¦¦à§à¦¦à¦¾ (Tasdid) à¦šà§‡à¦• à¦«à¦¾à¦‚à¦¶à¦¨
# # ========================================
# def has_shadda(text):
#     """à¦Ÿà§‡à¦•à§à¦¸à¦Ÿà§‡ à¦¶à¦¾à¦¦à§à¦¦à¦¾ (Ù€Ù‘) à¦†à¦›à§‡ à¦•à¦¿à¦¨à¦¾ à¦šà§‡à¦• à¦•à¦°à§‡"""
#     SHADDA = '\u0651'  # Unicode for Ø´ÙŽØ¯ÙŽÙ‘Ø©
#     return SHADDA in text

# # ========================================
# # 3. à¦…à¦¡à¦¿à¦“ à¦¥à§‡à¦•à§‡ à¦Ÿà§‡à¦•à§à¦¸à¦Ÿ à¦¤à§ˆà¦°à¦¿
# # ========================================
# def audio_to_text(audio_path, processor, model):
#     """
#     à¦…à¦¡à¦¿à¦“ à¦«à¦¾à¦‡à¦² à¦¥à§‡à¦•à§‡ à¦†à¦°à¦¬à¦¿ à¦Ÿà§‡à¦•à§à¦¸à¦Ÿ à¦¤à§ˆà¦°à¦¿ à¦•à¦°à§‡
#     :param audio_path: à¦…à¦¡à¦¿à¦“ à¦«à¦¾à¦‡à¦²à§‡à¦° à¦ªà¦¾à¦¥
#     :param processor: Wav2Vec2 à¦ªà§à¦°à¦¸à§‡à¦¸à¦°
#     :param model: Wav2Vec2 à¦®à¦¡à§‡à¦²
#     :return: à¦Ÿà§à¦°à¦¾à¦¨à§à¦¸à¦•à§à¦°à¦¾à¦‡à¦¬à¦¡ à¦Ÿà§‡à¦•à§à¦¸à¦Ÿ
#     """
#     try:
#         speech, rate = torchaudio.load(audio_path)
#     except Exception as e:
#         print("âŒ à¦…à¦¡à¦¿à¦“ à¦«à¦¾à¦‡à¦² à¦²à§‹à¦¡ à¦•à¦°à¦¤à§‡ à¦¬à§à¦¯à¦°à§à¦¥:", str(e))
#         exit(1)

#     # 16kHz à¦ à¦°à¦¿à¦¸à§à¦¯à¦¾à¦®à§à¦ªà¦² (Wav2Vec2 à¦à¦° à¦œà¦¨à§à¦¯ à¦œà¦°à§à¦°à¦¿)
#     if rate != 16000:
#         resampler = torchaudio.transforms.Resample(orig_freq=rate, new_freq=16000)
#         speech = resampler(speech)
#     speech = speech.squeeze().numpy()

#     # à¦®à¦¡à§‡à¦² à¦‡à¦¨à¦ªà§à¦Ÿ
#     inputs = processor(speech, sampling_rate=16000, return_tensors="pt", padding=True)

#     # à¦Ÿà§à¦°à¦¾à¦¨à§à¦¸à¦•à§à¦°à¦¿à¦ªà¦¶à¦¨
#     with torch.no_grad():
#         logits = model(inputs.input_values).logits
#     predicted_ids = torch.argmax(logits, dim=-1)
#     transcription = processor.decode(predicted_ids[0])
#     return transcription.strip()

# # ========================================
# # 4. à¦‰à¦šà§à¦šà¦¾à¦°à¦£ à¦“ à¦¤à¦¾à¦¸à¦¦à§€à¦¦ à¦®à§‚à¦²à§à¦¯à¦¾à¦¯à¦¼à¦¨
# # ========================================
# def check_pronunciation_and_tasdid(user_audio, reference_text, processor, model):
#     """
#     à¦‰à¦šà§à¦šà¦¾à¦°à¦£ à¦“ à¦¶à¦¾à¦¦à§à¦¦à¦¾ à¦šà§‡à¦• à¦•à¦°à§‡
#     """
#     print("ðŸ”Š à¦…à¦¡à¦¿à¦“ à¦¥à§‡à¦•à§‡ à¦Ÿà§‡à¦•à§à¦¸à¦Ÿ à¦¤à§ˆà¦°à¦¿ à¦¹à¦šà§à¦›à§‡...")
#     user_text = audio_to_text(user_audio, processor, model)
#     print(f"ðŸ—£ï¸ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦°à¦•à¦¾à¦°à§€ à¦¬à¦²à§‡à¦›à§‡à¦¨: {user_text}")
#     print(f"ðŸ“– à¦¸à¦ à¦¿à¦• à¦†à¦¯à¦¼à¦¾à¦¤: {reference_text}")

#     # à¦®à¦¿à¦² à¦¸à§à¦•à§‹à¦°
#     similarity = fuzz.ratio(user_text, reference_text)
#     print(f"\nðŸ“Š à¦®à¦¿à¦²: {similarity}%")

#     # à¦¶à¦¾à¦¦à§à¦¦à¦¾ à¦šà§‡à¦•
#     ref_has = has_shadda(reference_text)
#     user_has = has_shadda(user_text)

#     print(f"\nðŸ” à¦¶à¦¾à¦¦à§à¦¦à¦¾ à¦ªà¦°à§€à¦•à§à¦·à¦¾:")
#     print(f"  à¦¸à¦ à¦¿à¦• à¦Ÿà§‡à¦•à§à¦¸à¦Ÿà§‡ à¦¶à¦¾à¦¦à§à¦¦à¦¾ à¦†à¦›à§‡: {ref_has}")
#     print(f"  à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦°à¦•à¦¾à¦°à§€à¦° à¦Ÿà§‡à¦•à§à¦¸à¦Ÿà§‡ à¦¶à¦¾à¦¦à§à¦¦à¦¾ à¦†à¦›à§‡: {user_has}")

#     if ref_has and not user_has:
#         print("âŒ âš ï¸ à¦¤à¦¾à¦¸à¦¦à§€à¦¦ (à¦¶à¦¾à¦¦à§à¦¦à¦¾) à¦‰à¦šà§à¦šà¦¾à¦°à¦£ à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à¦¨à¦¿!")
#     elif ref_has and user_has:
#         print("âœ… à¦¶à¦¾à¦¦à§à¦¦à¦¾ à¦ à¦¿à¦• à¦†à¦›à§‡à¥¤")
#     else:
#         print("â„¹ï¸ à¦¶à¦¾à¦¦à§à¦¦à¦¾ à¦²à¦¾à¦—à§‡ à¦¨à¦¾à¥¤")

#     # à¦ªà¦¾à¦°à§à¦¥à¦•à§à¦¯ à¦¦à§‡à¦–à¦¾à¦¨à§‹
#     matcher = SequenceMatcher(None, reference_text, user_text)
#     print("\nðŸ“Œ à¦ªà¦¾à¦°à§à¦¥à¦•à§à¦¯:")
#     for tag, i1, i2, j1, j2 in matcher.get_opcodes():
#         if tag != 'equal':
#             print(f"  [{tag.upper()}] '{reference_text[i1:i2]}' â†’ '{user_text[j1:j2]}'")

#     return {
#         "user_text": user_text,
#         "similarity": similarity,
#         "shadda_correct": ref_has == user_has,
#         "details": {
#             "reference_has_shadda": ref_has,
#             "user_has_shadda": user_has
#         }
#     }

# # ========================================
# # 5. à¦®à§‚à¦² à¦ªà§à¦°à§‹à¦—à§à¦°à¦¾à¦®
# # ========================================
# if __name__ == "__main__":
#     # ðŸ”§ à¦†à¦ªà¦¨à¦¾à¦° à¦¡à§‡à¦Ÿà¦¾ à¦à¦–à¦¾à¦¨à§‡ à¦¦à¦¿à¦¨
#     AUDIO_FILE = "./1. Surah Al-Fatihah 1st verse.mp3"  # à¦†à¦ªà¦¨à¦¾à¦° à¦…à¦¡à¦¿à¦“ à¦«à¦¾à¦‡à¦²
#     CORRECT_AYAH = "Ø¨ÙØ³Ù’Ù…Ù Ø§Ù„Ù„ÙŽÙ‘Ù‡Ù Ø§Ù„Ø±ÙŽÙ‘Ø­Ù’Ù…ÙŽÙ°Ù†Ù Ø§Ù„Ø±ÙŽÙ‘Ø­ÙÙŠÙ…Ù"  # à¦¸à¦ à¦¿à¦• à¦†à¦¯à¦¼à¦¾à¦¤ (à¦¶à¦¾à¦¦à§à¦¦à¦¾ à¦¸à¦¹)

#     print("ðŸŽ¯ à¦‰à¦šà§à¦šà¦¾à¦°à¦£ à¦“ à¦¤à¦¾à¦¸à¦¦à§€à¦¦ à¦šà§‡à¦• à¦¶à§à¦°à§ à¦¹à¦šà§à¦›à§‡...\n")
    
#     result = check_pronunciation_and_tasdid(AUDIO_FILE, CORRECT_AYAH, processor, model)

#     print("\nâœ… à¦šà§‡à¦• à¦¸à¦®à§à¦ªà¦¨à§à¦¨!")
#     print(f"à¦¸à¦¾à¦®à¦—à§à¦°à¦¿à¦• à¦®à¦¿à¦²: {result['similarity']}%")
#     if result['shadda_correct']:
#         print("ðŸŽ‰ à¦¶à¦¾à¦¦à§à¦¦à¦¾ à¦ à¦¿à¦• à¦†à¦›à§‡à¥¤")
#     else:
#         print("ðŸ”´ à¦¶à¦¾à¦¦à§à¦¦à¦¾ à¦­à§à¦² à¦¹à¦¯à¦¼à§‡à¦›à§‡à¥¤")








































#  pip install torch torchaudio transformers librosa fuzzywuzzy python-Levenshtein



# -*- coding: utf-8 -*-
"""
Quran Recitation: Pronunciation & Shadda (Tasdid) Checker
--------------------------------------------------------
This script:
- Transcribes Arabic speech from audio using a fine-tuned Wav2Vec2 model
- Checks if Shadda (Ù€Ù‘) is present in both reference and transcription
- Compares similarity using fuzzy matching
- Highlights differences
- Works reliably with torchaudio (no experimental libraries)
"""

import torch
import torchaudio
from transformers import AutoProcessor, Wav2Vec2ForCTC
from fuzzywuzzy import fuzz
from difflib import SequenceMatcher
import warnings

# Suppress torchaudio deprecation warning (safe for now)
warnings.filterwarnings("ignore", category=UserWarning, module="torchaudio")

# ========================================
# 1. Load Arabic-Optimized Model
# ========================================
print("ðŸ”„ Loading Arabic-optimized model...")
try:
    processor = AutoProcessor.from_pretrained("jonatasgrosman/wav2vec2-large-xlsr-53-arabic")
    model = Wav2Vec2ForCTC.from_pretrained("jonatasgrosman/wav2vec2-large-xlsr-53-arabic")
    print("âœ… Model loaded Successfully!")
except Exception as e:
    print("âŒ Failed to load model:", str(e))
    print("ðŸ’¡ Check internet, use a VPN, or download model manually.")
    exit(1)

# ========================================
# 2. Shadda (Tasdid) Detection
# ========================================
def has_shadda(text):
    """Check if the text contains Shadda (Ù€Ù‘)"""
    SHADDA = '\u0651'  # Unicode for Ù€Ù‘
    return SHADDA in text

# ========================================
# 3. Audio to Text (Using torchaudio - Stable & Reliable)
# ========================================
def audio_to_text(audio_path, processor, model):
    """
    Load audio and transcribe using Wav2Vec2
    :param audio_path: Path to audio file (.mp3, .wav)
    :return: Transcribed Arabic text
    """
    try:
        speech, rate = torchaudio.load(audio_path)
    except Exception as e:
        print("âŒ Failed to load audio file:", str(e))
        exit(1)

    # Resample to 16kHz (required by Wav2Vec2)
    if rate != 16000:
        resampler = torchaudio.transforms.Resample(orig_freq=rate, new_freq=16000)
        speech = resampler(speech)
    speech = speech.squeeze().numpy()  # Convert to 1D array

    # Process input
    inputs = processor(speech, sampling_rate=16000, return_tensors="pt", padding=True)

    # Inference
    with torch.no_grad():
        logits = model(inputs.input_values).logits
    predicted_ids = torch.argmax(logits, dim=-1)
    transcription = processor.decode(predicted_ids[0])
    return transcription.strip()

# ========================================
# 4. Evaluate Pronunciation & Shadda
# ========================================
def check_pronunciation_and_tasdid(user_audio, reference_text, processor, model):
    """
    Full evaluation of user's recitation
    """
    print("ðŸ”Š Transcribing user audio...")
    user_text = audio_to_text(user_audio, processor, model)
    print(f"ðŸ—£ï¸ User said: {user_text}")
    print(f"ðŸ“– Reference: {reference_text}")

    # Similarity score
    similarity = fuzz.ratio(user_text, reference_text) # i will use partial_ratio
    print(f"\nðŸ“Š Similarity Score: {similarity}%")

    # Shadda check
    ref_has = has_shadda(reference_text)
    user_has = has_shadda(user_text)

    print(f"\nðŸ” Shadda (Tasdid) Check:")
    print(f"  Reference has Shadda: {ref_has}")
    print(f"  User transcription has Shadda: {user_has}")

    if ref_has and not user_has:
        print("âŒ âš ï¸ Warning: Shadda is missing! It should be pronounced.")
    elif ref_has and user_has:
        print("âœ… Shadda is correctly present.")
    else:
        print("â„¹ï¸ No Shadda required.")

    # Highlight differences
    matcher = SequenceMatcher(None, reference_text, user_text)
    print("\nðŸ“Œ Differences:")
    for tag, i1, i2, j1, j2 in matcher.get_opcodes():
        if tag != 'equal':
            print(f"  [{tag.upper()}] '{reference_text[i1:i2]}' â†’ '{user_text[j1:j2]}'")

    return {
        "user_text": user_text,
        "similarity": similarity,
        "shadda_correct": ref_has == user_has,
        "details": {
            "reference_has_shadda": ref_has,
            "user_has_shadda": user_has
        }
    }

# ========================================
# 5. Main Execution
# ========================================
if __name__ == "__main__":
    # ðŸ”§ Configure your inputs
    AUDIO_FILE = "./1.mp3"
    CORRECT_AYAH ="Ø¨ÙØ³Û¡Ù…Ù Ù±Ù„Ù„Ù‘ÙŽÙ‡Ù Ù±Ù„Ø±Ù‘ÙŽØ­Û¡Ù…ÙŽÙ€Ù°Ù†Ù Ù±Ù„Ø±Ù‘ÙŽØ­ÙÛŒÙ…Ù" # teacher's pronunciation
    print("ðŸŽ¯ Starting pronunciation and Tasdid check...\n")
    
    result = check_pronunciation_and_tasdid(AUDIO_FILE, CORRECT_AYAH, processor, model)

    print("\nâœ… Evaluation Complete!")
    print(f"Overall Similarity: {result['similarity']}%")
    if result['shadda_correct']:
        print("ðŸŽ‰ Shadda is correctly used.")
    else:
        print("ðŸ”´ Shadda is missing or incorrectly applied.")